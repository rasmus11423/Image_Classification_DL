{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Food-101 Download & Setup\n",
        "\n",
        "This notebook downloads the Food-101 dataset and prepares a local folder layout usable by the training notebook. It also lets you define a subset of 30–50 classes and saves a `config.json` you can reuse.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: C:\\Users\\Name\\OneDrive - The University of Texas at Austin\\UT Austin-DEVICE\\Deep L\\Mini Project\\Image_Classification_DL\n",
            "Data dir: C:\\Users\\Name\\OneDrive - The University of Texas at Austin\\UT Austin-DEVICE\\Deep L\\Mini Project\\Image_Classification_DL\\data\n"
          ]
        }
      ],
      "source": [
        "import os, json, zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(r\"C:/Users/Name/OneDrive - The University of Texas at Austin/UT Austin-DEVICE/Deep L/Mini Project/Image_Classification_DL\")\n",
        "DATA_DIR = PROJECT_ROOT / \"data\"\n",
        "FOOD101_DIR = DATA_DIR / \"food-101\"\n",
        "CONFIG_PATH = PROJECT_ROOT / \"config.json\"\n",
        "\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"Project root:\", PROJECT_ROOT)\n",
        "print(\"Data dir:\", DATA_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensuring Food-101 is present via torchvision downloader...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.00G/5.00G [14:09<00:00, 5.88MB/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting KaggleHub (optional)...\n",
            "Resuming download from 9458155520 bytes (608903612 bytes left)...\n",
            "Resuming download from https://www.kaggle.com/api/v1/datasets/download/dansbecker/food-101?dataset_version_number=1 (9458155520/10067059132) bytes left.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.38G/9.38G [00:44<00:00, 13.7MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkagglehub\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting KaggleHub (optional)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m cache \u001b[38;5;241m=\u001b[39m Path(\u001b[43mkagglehub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_download\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdansbecker/food-101\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     15\u001b[0m zip_path \u001b[38;5;241m=\u001b[39m cache \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfood-101.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m zip_path\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (DATA_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfood-101\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists():\n",
            "File \u001b[1;32mc:\\Users\\Name\\anaconda3\\envs\\DeepL\\lib\\site-packages\\kagglehub\\datasets.py:43\u001b[0m, in \u001b[0;36mdataset_download\u001b[1;34m(handle, path, force_download)\u001b[0m\n\u001b[0;32m     41\u001b[0m h \u001b[38;5;241m=\u001b[39m parse_dataset_handle(handle)\n\u001b[0;32m     42\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;241m.\u001b[39mto_url()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m, extra\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mEXTRA_CONSOLE_BLOCK})\n\u001b[1;32m---> 43\u001b[0m path, _ \u001b[38;5;241m=\u001b[39m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_resolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
            "File \u001b[1;32mc:\\Users\\Name\\anaconda3\\envs\\DeepL\\lib\\site-packages\\kagglehub\\registry.py:28\u001b[0m, in \u001b[0;36mMultiImplRegistry.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m impl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impls):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mis_supported(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m         fails\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtype\u001b[39m(impl)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Name\\anaconda3\\envs\\DeepL\\lib\\site-packages\\kagglehub\\resolver.py:29\u001b[0m, in \u001b[0;36mResolver.__call__\u001b[1;34m(self, handle, path, force_download)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m, handle: T, path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, force_download: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     17\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Optional[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resolves a handle into a path with the requested file(s) and the resource's version number.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m        Some cases where version number might be missing: Competition datasource, API-based models.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     path, version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     register_datasource_access(handle, version)\n",
            "File \u001b[1;32mc:\\Users\\Name\\anaconda3\\envs\\DeepL\\lib\\site-packages\\kagglehub\\http_resolver.py:132\u001b[0m, in \u001b[0;36mDatasetHttpResolver._resolve\u001b[1;34m(self, h, path, force_download)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# First, we download the archive.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m api_client\u001b[38;5;241m.\u001b[39mdownload_file(url_path, archive_path, h)\n\u001b[1;32m--> 132\u001b[0m \u001b[43m_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43marchive_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Delete the archive\u001b[39;00m\n\u001b[0;32m    135\u001b[0m os\u001b[38;5;241m.\u001b[39mremove(archive_path)\n",
            "File \u001b[1;32mc:\\Users\\Name\\anaconda3\\envs\\DeepL\\lib\\site-packages\\kagglehub\\http_resolver.py:269\u001b[0m, in \u001b[0;36m_extract_archive\u001b[1;34m(archive_path, out_path)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mis_zipfile(archive_path):\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(archive_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 269\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported archive type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\Name\\anaconda3\\envs\\DeepL\\lib\\zipfile.py:1660\u001b[0m, in \u001b[0;36mZipFile.extractall\u001b[1;34m(self, path, members, pwd)\u001b[0m\n\u001b[0;32m   1657\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(path)\n\u001b[0;32m   1659\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m zipinfo \u001b[38;5;129;01min\u001b[39;00m members:\n\u001b[1;32m-> 1660\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzipinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Name\\anaconda3\\envs\\DeepL\\lib\\zipfile.py:1715\u001b[0m, in \u001b[0;36mZipFile._extract_member\u001b[1;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[0;32m   1711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n\u001b[0;32m   1713\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(member, pwd\u001b[38;5;241m=\u001b[39mpwd) \u001b[38;5;28;01mas\u001b[39;00m source, \\\n\u001b[0;32m   1714\u001b[0m      \u001b[38;5;28mopen\u001b[39m(targetpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m target:\n\u001b[1;32m-> 1715\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n",
            "File \u001b[1;32mc:\\Users\\Name\\anaconda3\\envs\\DeepL\\lib\\shutil.py:187\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m                 fdst_write(mv)\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcopyfileobj\u001b[39m(fsrc, fdst, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# Localize variable access to minimize overhead.\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Download using torchvision (guarded)\n",
        "from pathlib import Path\n",
        "\n",
        "def has_images_meta(p: Path) -> bool:\n",
        "    return (p / \"images\").exists() and (p / \"meta\").exists()\n",
        "\n",
        "if not has_images_meta(FOOD101_DIR):\n",
        "    from torchvision.datasets import Food101 as TVFood101\n",
        "    print(\"Downloading Food-101 via torchvision (first run may take a while)...\")\n",
        "    _ = TVFood101(root=str(DATA_DIR), download=True)\n",
        "else:\n",
        "    print(\"Food-101 already present; skipping download.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resolved FOOD-101 root: C:\\Users\\Name\\OneDrive - The University of Texas at Austin\\UT Austin-DEVICE\\Deep L\\Mini Project\\Image_Classification_DL\\data\\food-101\n",
            "Subdirs: ['images', 'license_agreement.txt', 'meta', 'README.txt']\n"
          ]
        }
      ],
      "source": [
        "# Resolve root with images/ and meta/\n",
        "from pathlib import Path\n",
        "\n",
        "def has_images_meta(p: Path) -> bool:\n",
        "    return (p / \"images\").exists() and (p / \"meta\").exists()\n",
        "\n",
        "ROOT = None\n",
        "candidates = [FOOD101_DIR, DATA_DIR / \"food-101\", *(p for p in DATA_DIR.glob(\"**/food-101\"))]\n",
        "for cand in candidates:\n",
        "    if has_images_meta(cand):\n",
        "        ROOT = cand\n",
        "        break\n",
        "\n",
        "if ROOT is None:\n",
        "    raise FileNotFoundError(\n",
        "        \"Could not find 'food-101' with images/ and meta/ under data dir after download attempts.\\n\"\n",
        "        f\"Please place it manually under: {DATA_DIR}\"\n",
        "    )\n",
        "\n",
        "print(\"Resolved FOOD-101 root:\", ROOT)\n",
        "print(\"Subdirs:\", os.listdir(ROOT))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote config: C:\\Users\\Name\\OneDrive - The University of Texas at Austin\\UT Austin-DEVICE\\Deep L\\Mini Project\\Image_Classification_DL\\config.json\n",
            "{'dataset_root': 'C:\\\\Users\\\\Name\\\\OneDrive - The University of Texas at Austin\\\\UT Austin-DEVICE\\\\Deep L\\\\Mini Project\\\\Image_Classification_DL\\\\data\\\\food-101', 'class_names': ['apple_pie', 'beef_carpaccio', 'beef_tartare', 'caesar_salad', 'caprese_salad', 'carrot_cake', 'cheesecake', 'club_sandwich', 'creme_brulee', 'croque_madame', 'cup_cakes', 'donuts', 'escargots', 'hamburger', 'hot_and_sour_soup', 'hummus', 'miso_soup', 'oysters', 'paella', 'pho', 'pork_chop', 'ramen', 'samosa', 'sashimi', 'shrimp_and_grits', 'spaghetti_bolognese', 'strawberry_shortcake', 'tacos', 'takoyaki', 'tiramisu'], 'image_size': 128, 'split_protocol': 'standard', 'seed': 42}\n"
          ]
        }
      ],
      "source": [
        "# Select subset of classes and write config.json\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "all_classes = sorted(os.listdir(ROOT / \"images\"))\n",
        "subset_size = 30  # change to 30–50 as needed\n",
        "if subset_size > len(all_classes):\n",
        "    subset_size = len(all_classes)\n",
        "selected_classes = sorted(random.sample(all_classes, k=subset_size))\n",
        "\n",
        "config = {\n",
        "    \"dataset_root\": str(ROOT),\n",
        "    \"class_names\": selected_classes,\n",
        "    \"image_size\": 128,\n",
        "    \"split_protocol\": \"standard\",\n",
        "    \"seed\": 42,\n",
        "}\n",
        "with open(CONFIG_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(\"Wrote config:\", CONFIG_PATH)\n",
        "print(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DeepL",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
