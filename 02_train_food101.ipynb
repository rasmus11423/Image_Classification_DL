{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Food-101 Training: Scratch, Transfer (Linear Probe), Fine-tune\n",
        "\n",
        "This notebook loads the config, builds dataloaders with augmentation and imbalance handling, and trains:\n",
        "- Scratch: SimpleCNN / ResNet-18 from scratch\n",
        "- Transfer: ResNet-50 or ResNet-18 frozen backbone (linear probe)\n",
        "- Fine-tune: Unfreeze last stage(s)\n",
        "\n",
        "It also computes accuracy, macro-F1, and shows confusion matrices and augmentation impact.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded config: {'dataset_root': 'C:\\\\Users\\\\Name\\\\OneDrive - The University of Texas at Austin\\\\UT Austin-DEVICE\\\\Deep L\\\\Mini Project\\\\Image_Classification_DL\\\\data\\\\food-101', 'class_names': ['apple_pie', 'beef_carpaccio', 'beef_tartare', 'caesar_salad', 'caprese_salad', 'carrot_cake', 'cheesecake', 'club_sandwich', 'creme_brulee', 'croque_madame', 'cup_cakes', 'donuts', 'escargots', 'hamburger', 'hot_and_sour_soup', 'hummus', 'miso_soup', 'oysters', 'paella', 'pho', 'pork_chop', 'ramen', 'samosa', 'sashimi', 'shrimp_and_grits', 'spaghetti_bolognese', 'strawberry_shortcake', 'tacos', 'takoyaki', 'tiramisu'], 'image_size': 128, 'split_protocol': 'standard', 'seed': 42}\n"
          ]
        }
      ],
      "source": [
        "import os, json, math, random\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Optional, Dict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models as tvm\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "PROJECT_ROOT = Path(r\"C:/Users/Name/OneDrive - The University of Texas at Austin/UT Austin-DEVICE/Deep L/Mini Project/Image_Classification_DL\") #Change based on your own path\n",
        "CONFIG_PATH = PROJECT_ROOT / \"config.json\"\n",
        "\n",
        "with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    cfg = json.load(f)\n",
        "\n",
        "FOOD101_ROOT = Path(cfg[\"dataset_root\"])  # has images/ and meta/\n",
        "CLASS_NAMES: List[str] = cfg[\"class_names\"]\n",
        "IMAGE_SIZE: int = int(cfg.get(\"image_size\", 128))\n",
        "SPLIT_PROTOCOL: str = cfg.get(\"split_protocol\", \"standard\")\n",
        "SEED: int = int(cfg.get(\"seed\", 42))\n",
        "\n",
        "print(\"Loaded config:\", cfg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transformer for working with image pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reusable transforms with augmentation toggle\n",
        "\n",
        "def build_transforms(image_size: int, train: bool, use_aug: bool):\n",
        "    if train:\n",
        "        aug = []\n",
        "        if use_aug:\n",
        "            aug = [\n",
        "                T.RandomResizedCrop(image_size, scale=(0.7, 1.0)),\n",
        "                T.RandomHorizontalFlip(p=0.5),\n",
        "                T.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "                T.RandomRotation(degrees=10),\n",
        "            ]\n",
        "        base = [T.Resize((image_size, image_size))]\n",
        "        norm = [T.ToTensor(), T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])]\n",
        "        return T.Compose(aug + base + norm)\n",
        "    else:\n",
        "        return T.Compose([\n",
        "            T.Resize((image_size, image_size)),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "        ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data standardization and stratified splitting (880 img train, 200 val per class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset utilities (standard or stratified split)\n",
        "class FoodDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, items: List[Tuple[str, int]], transform=None, class_names: Optional[List[str]] = None):\n",
        "        self.items = items\n",
        "        self.transform = transform\n",
        "        self.class_names = class_names\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.items[idx]\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "\n",
        "def _read_standard_split_lists(root: Path) -> Dict[str, List[str]]:\n",
        "    meta = root / \"meta\"\n",
        "    with open(meta / \"train.txt\") as f:\n",
        "        train_stems = [l.strip() for l in f if l.strip()]\n",
        "    with open(meta / \"test.txt\") as f:\n",
        "        test_stems = [l.strip() for l in f if l.strip()]\n",
        "    return {\"train\": train_stems, \"test\": test_stems}\n",
        "\n",
        "\n",
        "def build_items_standard(root: Path, class_names: List[str], split: str) -> List[Tuple[str, int]]:\n",
        "    stems = _read_standard_split_lists(root)[\"train\" if split == \"train\" else \"test\"]\n",
        "    class_to_idx = {c: i for i, c in enumerate(class_names)}\n",
        "    images_dir = root / \"images\"\n",
        "    items: List[Tuple[str, int]] = []\n",
        "    for s in stems:\n",
        "        cls, stem = s.split(\"/\")\n",
        "        if cls in class_to_idx:\n",
        "            items.append((str(images_dir / cls / f\"{stem}.jpg\"), class_to_idx[cls]))\n",
        "    return items\n",
        "\n",
        "\n",
        "def build_items_stratified(root: Path, class_names: List[str], train_ratio: float = 0.8, seed: int = 42):\n",
        "    rng = random.Random(seed)\n",
        "    class_to_idx = {c: i for i, c in enumerate(class_names)}\n",
        "    images_dir = root / \"images\"\n",
        "\n",
        "    train_items, val_items = [], []\n",
        "    for cls in class_names:\n",
        "        cls_dir = images_dir / cls\n",
        "        paths = [str(cls_dir / fn) for fn in os.listdir(cls_dir) if fn.lower().endswith(\".jpg\")]\n",
        "        rng.shuffle(paths)\n",
        "        k = int(len(paths) * train_ratio)\n",
        "        li = class_to_idx[cls]\n",
        "        train_items.extend([(p, li) for p in paths[:k]])\n",
        "        val_items.extend([(p, li) for p in paths[k:]])\n",
        "    return train_items, val_items\n",
        "\n",
        "\n",
        "def build_loaders(root: Path, class_names: List[str], image_size: int, batch_size: int, num_workers: int,\n",
        "                  split_protocol: str, use_aug: bool, use_imbalance_sampler: bool):\n",
        "    if split_protocol == \"standard\":\n",
        "        train_items = build_items_standard(root, class_names, split=\"train\")\n",
        "        val_items   = build_items_standard(root, class_names, split=\"test\")\n",
        "    else:\n",
        "        train_items, val_items = build_items_stratified(root, class_names, train_ratio=0.8, seed=SEED)\n",
        "\n",
        "    t_train = build_transforms(image_size, train=True, use_aug=use_aug)\n",
        "    t_val   = build_transforms(image_size, train=False, use_aug=False)\n",
        "    ds_train = FoodDataset(train_items, transform=t_train, class_names=class_names)\n",
        "    ds_val   = FoodDataset(val_items,   transform=t_val,   class_names=class_names)\n",
        "\n",
        "    if use_imbalance_sampler:\n",
        "        counts = np.zeros(len(class_names), dtype=np.int64)\n",
        "        for _, y in train_items:\n",
        "            counts[y] += 1\n",
        "        class_weights = 1.0 / np.maximum(counts, 1)\n",
        "        sample_weights = np.array([class_weights[y] for _, y in train_items], dtype=np.float32)\n",
        "        sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "        train_loader = DataLoader(ds_train, batch_size=batch_size, sampler=sampler, num_workers=num_workers, pin_memory=True)\n",
        "    else:\n",
        "        train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    val_loader = DataLoader(ds_val, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "    return train_loader, val_loader, len(class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training and validation functions for all 3 models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training utilities\n",
        "\n",
        "def accuracy(logits, targets):\n",
        "    return (logits.argmax(1) == targets).float().mean().item()\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, criterion):\n",
        "    model.train()\n",
        "    loss_sum = acc_sum = n = 0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        b = xb.size(0)\n",
        "        loss_sum += loss.item() * b\n",
        "        acc_sum  += accuracy(logits, yb) * b\n",
        "        n += b\n",
        "    return {\"loss\": loss_sum / n, \"acc\": acc_sum / n}\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, loader, device, criterion):\n",
        "    model.eval()\n",
        "    loss_sum = acc_sum = n = 0\n",
        "    all_targets, all_preds = [], []\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        preds = logits.argmax(1)\n",
        "        all_targets.extend(yb.detach().cpu().tolist())\n",
        "        all_preds.extend(preds.detach().cpu().tolist())\n",
        "        b = xb.size(0)\n",
        "        loss_sum += loss.item() * b\n",
        "        acc_sum  += accuracy(logits, yb) * b\n",
        "        n += b\n",
        "    macro_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "    return {\"loss\": loss_sum / n, \"acc\": acc_sum / n, \"macro_f1\": macro_f1, \"targets\": all_targets, \"preds\": all_preds}\n",
        "\n",
        "\n",
        "def plot_confusion(labels_true, labels_pred, class_names: List[str], title: str):\n",
        "    cm = confusion_matrix(labels_true, labels_pred, labels=list(range(len(class_names))))\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=False, cmap=\"Blues\", fmt=\"d\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Models: SimpleCNN and ResNet18/50 wrappers\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "class ResNetWrapper(nn.Module):\n",
        "    def __init__(self, backbone: str, num_classes: int, pretrained: bool, freeze_backbone: bool, unfreeze_from_layer: Optional[str] = None):\n",
        "        super().__init__()\n",
        "        if backbone == \"resnet18\":\n",
        "            base = tvm.resnet18(weights=tvm.ResNet18_Weights.DEFAULT if pretrained else None)\n",
        "        elif backbone == \"resnet50\":\n",
        "            base = tvm.resnet50(weights=tvm.ResNet50_Weights.DEFAULT if pretrained else None)\n",
        "        else:\n",
        "            raise ValueError(\"backbone must be 'resnet18' or 'resnet50'\")\n",
        "        in_feats = base.fc.in_features\n",
        "        base.fc = nn.Linear(in_feats, num_classes)\n",
        "        self.backbone = base\n",
        "\n",
        "        if freeze_backbone:\n",
        "            for name, p in self.backbone.named_parameters():\n",
        "                p.requires_grad = (name.startswith(\"fc\"))\n",
        "\n",
        "        if unfreeze_from_layer is not None:\n",
        "            passed = False\n",
        "            for name, module in self.backbone.named_children():\n",
        "                if name == unfreeze_from_layer:\n",
        "                    passed = True\n",
        "                if passed or name == \"fc\":\n",
        "                    for p in module.parameters():\n",
        "                        p.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "\n",
        "# custom optimizer for the backbone and head\n",
        "def build_optimizer(model: nn.Module, lr_head: float = 1e-3, lr_backbone: float = 1e-4, weight_decay: float = 1e-4):\n",
        "    head_params, backbone_params = [], []\n",
        "    for name, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        if \"fc\" in name or \"classifier\" in name:\n",
        "            head_params.append(p)\n",
        "        else:\n",
        "            backbone_params.append(p)\n",
        "    params = [\n",
        "        {\"params\": head_params, \"lr\": lr_head},\n",
        "        {\"params\": backbone_params, \"lr\": lr_backbone},\n",
        "    ]\n",
        "    opt = optim.AdamW(params, lr=lr_head, weight_decay=weight_decay)\n",
        "    return opt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train runners for the three regimes\n",
        "\n",
        "def run_training(model: nn.Module, train_loader, val_loader, epochs: int, lr_head: float, lr_backbone: float, label: str):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = build_optimizer(model, lr_head=lr_head, lr_backbone=lr_backbone)\n",
        "\n",
        "    history = []\n",
        "    for ep in range(epochs):\n",
        "        tr = train_one_epoch(model, train_loader, optimizer, device, criterion)\n",
        "        va = validate(model, val_loader, device, criterion)\n",
        "        history.append({\"epoch\": ep, **{f\"train_{k}\": v for k, v in tr.items()}, **{f\"val_{k}\": v for k, v in va.items()}})\n",
        "        print(f\"[{label}] Epoch {ep+1}/{epochs} | train_loss={tr['loss']:.4f} acc={tr['acc']:.3f} | val_loss={va['loss']:.4f} acc={va['acc']:.3f} macroF1={va['macro_f1']:.3f}\")\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def train_regimes(train_loader, val_loader, num_classes: int, image_size: int):\n",
        "    results = {}\n",
        "\n",
        "    # Scratch: SimpleCNN or ResNet18(weights=None)\n",
        "    scratch_model = SimpleCNN(num_classes)\n",
        "    results['scratch'] = run_training(scratch_model, train_loader, val_loader, epochs=10, lr_head=1e-3, lr_backbone=1e-3, label=\"scratch\")\n",
        "\n",
        "    # Transfer (Linear Probe): freeze backbone\n",
        "    transfer_model = ResNetWrapper(backbone=\"resnet50\", num_classes=num_classes, pretrained=True, freeze_backbone=True)\n",
        "    results['transfer'] = run_training(transfer_model, train_loader, val_loader, epochs=10, lr_head=1e-3, lr_backbone=1e-5, label=\"transfer\")\n",
        "\n",
        "    # Fine-tune: unfreeze last block\n",
        "    finetune_model = ResNetWrapper(backbone=\"resnet50\", num_classes=num_classes, pretrained=True, freeze_backbone=False, unfreeze_from_layer=\"layer4\")\n",
        "    results['finetune'] = run_training(finetune_model, train_loader, val_loader, epochs=10, lr_head=1e-3, lr_backbone=1e-4, label=\"finetune\")\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_classes: 30\n"
          ]
        }
      ],
      "source": [
        "# Build loaders for two settings: no-aug vs aug + imbalance handling\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "train_loader_noaug, val_loader_noaug, num_classes = build_loaders(\n",
        "    FOOD101_ROOT, CLASS_NAMES, IMAGE_SIZE, BATCH_SIZE, NUM_WORKERS, SPLIT_PROTOCOL, use_aug=False, use_imbalance_sampler=False)\n",
        "\n",
        "train_loader_aug, val_loader_aug, _ = build_loaders(\n",
        "    FOOD101_ROOT, CLASS_NAMES, IMAGE_SIZE, BATCH_SIZE, NUM_WORKERS, SPLIT_PROTOCOL, use_aug=True, use_imbalance_sampler=True)\n",
        "\n",
        "print(\"num_classes:\", num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing the simpleCNN model and running for 3 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Name\\anaconda3\\envs\\DeepL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ],
      "source": [
        "# Quick start: train only SimpleCNN first (few epochs) and plot results\n",
        "EPOCHS = 3\n",
        "simple_model = SimpleCNN(num_classes)\n",
        "simple_model, simple_hist = run_training(\n",
        "    simple_model,\n",
        "    train_loader_noaug,  # start without augmentation for speed/determinism\n",
        "    val_loader_noaug,\n",
        "    epochs=EPOCHS,\n",
        "    lr_head=1e-3,\n",
        "    lr_backbone=1e-3,\n",
        "    label=\"simplecnn\",\n",
        ")\n",
        "\n",
        "last = simple_hist[-1]\n",
        "print({k: last[k] for k in [\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"val_macro_f1\"]})\n",
        "plot_confusion(last[\"targets\"], last[\"preds\"], CLASS_NAMES, title=\"Confusion Matrix: SimpleCNN (no aug)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running all 3 models together and plotting the results -DANGER TAKES A LONG TIME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Name\\anaconda3\\envs\\DeepL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ],
      "source": [
        "# Run: scratch / transfer / finetune for both settings and compare macro-F1\n",
        "results_noaug = train_regimes(train_loader_noaug, val_loader_noaug, num_classes, IMAGE_SIZE)\n",
        "results_aug   = train_regimes(train_loader_aug,   val_loader_aug,   num_classes, IMAGE_SIZE)\n",
        "\n",
        "# Collect macro-F1 from the last epoch of each regime\n",
        "regimes = [\"scratch\", \"transfer\", \"finetune\"]\n",
        "macroF1_noaug = {k: results_noaug[k][1][-1][\"val_macro_f1\"] for k in regimes}\n",
        "macroF1_aug   = {k: results_aug[k][1][-1][\"val_macro_f1\"]   for k in regimes}\n",
        "\n",
        "print(\"Macro-F1 (no aug):\", macroF1_noaug)\n",
        "#print(\"Macro-F1 (aug):\", macroF1_aug)\n",
        "\n",
        "# Plot comparison\n",
        "labels = regimes\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(x - width/2, [macroF1_noaug[k] for k in labels], width, label='No Aug')\n",
        "#plt.bar(x + width/2, [macroF1_aug[k] for k in labels], width, label='With Aug')\n",
        "plt.xticks(x, labels)\n",
        "plt.ylabel('Macro-F1')\n",
        "plt.title('Augmentation Impact by Regime')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Confusion matrix for best model (aug + finetune)\n",
        "va_best = results_aug['finetune'][1][-1]\n",
        "plot_confusion(va_best[\"targets\"], va_best[\"preds\"], CLASS_NAMES, title=\"Confusion Matrix: Fine-tune (aug)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DeepL",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
